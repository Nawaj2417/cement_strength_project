{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Concrete Compressive Strength.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age (day)  Concrete compressive strength   \n",
       "0            1040.0           676.0         28                       79.986111  \n",
       "1            1055.0           676.0         28                       61.887366  \n",
       "2             932.0           594.0        270                       40.269535  \n",
       "3             932.0           594.0        365                       41.052780  \n",
       "4             978.4           825.5        360                       44.296075  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "#  create a bar plot\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=missing_values, y= missing_values.values, color=\"red\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Missing values in Each column\")\n",
    "plt.ylabel(\"Number of Missing values\")\n",
    "plt.xlabel(\"columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "plt.figure(figsize=(16, 20))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    plt.subplot(len(cols) // 3 + 1, 3, i + 1)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"Boxplot for {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T05:03:15.814628Z",
     "iopub.status.busy": "2024-06-01T05:03:15.814262Z",
     "iopub.status.idle": "2024-06-01T05:03:15.819265Z",
     "shell.execute_reply": "2024-06-01T05:03:15.818320Z",
     "shell.execute_reply.started": "2024-06-01T05:03:15.814600Z"
    }
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA using pandas profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so from the above observations we have seen that, There is no Missing values , Outliers is present and duplicates values are there. so we need to work on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='0.2f', annot_kws={'size': 15}, linewidths=2, linecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights from correlation matrix\n",
    "1. Cement and concreate compressive strength :- Correlation is 0.50, which is moderate positive corrleation.\n",
    "2. Flyash and superplasticizer :- correlation is 0.38 , which is moderate positive correlation.\n",
    "3. Cement and water :- correlation is -0.08, which is very weak  negative correlation, suggesting there is no significant relationship between the amounts of water and cement used in the concrete mix.\n",
    "4. water and Superplasticizer :- correlation is -0.66, which is strong negative correlation ,suggesting that more superplasticizer is used in less water used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- indi -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot\n",
    "sns.pairplot(df,diag_kind = 'kde')\n",
    "plt.show()\n",
    "plt.savefig('pairplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T05:42:49.348901Z",
     "iopub.status.busy": "2024-06-01T05:42:49.348480Z",
     "iopub.status.idle": "2024-06-01T05:42:49.353892Z",
     "shell.execute_reply": "2024-06-01T05:42:49.352802Z",
     "shell.execute_reply.started": "2024-06-01T05:42:49.348869Z"
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def handle_outliers(df, threshold=5):\n",
    "    df_no_outliers = pd.DataFrame()\n",
    "    outliers = pd.DataFrame()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        z_scores = stats.zscore(df[col])\n",
    "        outlier_indices = (z_scores > threshold) | (z_scores < -threshold)\n",
    "        df_no_outliers[col] = df[col][~outlier_indices]\n",
    "        outliers[col] = df[col][outlier_indices]\n",
    "        \n",
    "    return df_no_outliers, outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers, outliers = handle_outliers(df, threshold=3)\n",
    "# Check for outliers\n",
    "if outliers.empty:\n",
    "    print(\"No outliers detected.\")\n",
    "else:\n",
    "    print(\"Outliers detected in the following columns:\")\n",
    "    print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_no_outliers, outliers])\n",
    "\n",
    "# Plot boxplots for each column to visualize the distribution\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=df_combined)\n",
    "plt.title(\"Boxplots of All Columns (with Outliers Removed)\")\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outlier using quartiles\n",
    "def handle_outliers_iqr(df, column_name, threshold=1.5):\n",
    "\n",
    "    # Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    \n",
    "    # Calculate the IQR (Interquartile Range)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    \n",
    "    # Find the indices of outliers based on the bounds\n",
    "    outlier_indices = (df[column_name] < lower_bound) | (df[column_name] > upper_bound)\n",
    "    \n",
    "    # Remove outliers from the DataFrame\n",
    "    df_no_outliers = df[~outlier_indices]\n",
    "    \n",
    "    # Store outliers in a separate DataFrame\n",
    "    outliers = df[outlier_indices]\n",
    "    \n",
    "    return df_no_outliers, outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the handle_outliers_iqr function to remove outliers from the 'Age (day)' column\n",
    "df_no_outliers_age, outliers_age = handle_outliers_iqr(df, 'Age (day)', threshold=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize box plot before outlier removal\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df['Age (day)'])\n",
    "plt.title(\"Boxplot of 'Age (day)' Column Before Outlier Removal\")\n",
    "plt.show()\n",
    "\n",
    "# Apply the handle_outliers_iqr function to remove outliers from the 'Age (day)' column\n",
    "df_no_outliers_age, outliers_age = handle_outliers_iqr(df, 'Age (day)', threshold=1)\n",
    "\n",
    "# Visualize box plot after outlier removal\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_no_outliers_age['Age (day)'])\n",
    "plt.title(\"Boxplot of 'Age (day)' Column After Outlier Removal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X, y, threshold=1.5):\n",
    "    Q1 = np.percentile(X, 25, axis=0)\n",
    "    Q3 = np.percentile(X, 75, axis=0)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    mask = np.logical_and(X >= lower_bound, X <= upper_bound)\n",
    "    mask = mask.all(axis=1)\n",
    "    return X[mask], y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent and Independent Variables\n",
    "X = df.iloc[:, :-1]\n",
    "y= df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = remove_outliers(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segreating numerical variables\n",
    "# numerical_cols = X.select_dtypes(exclude='object').columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary library\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Pipelines\n",
    "   \n",
    "    \n",
    "num_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "\n",
    "    ]\n",
    "        )\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train _test split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'DecisionTree': DecisionTreeRegressor(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor(),\n",
    "    'GradientBoosting': GradientBoostingRegressor(),\n",
    "    'XGBoost': xgb.XGBRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LinearRegression': {},\n",
    "    'Lasso': {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "        'l1_ratio': [0.1, 0.5, 0.7, 0.9, 1.0]},\n",
    "    'DecisionTree': {'max_depth': [None, 5, 10, 20]},\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10, 20]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]},\n",
    "    'GradientBoosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0], 'max_depth': [3, 5, 10]},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0], 'max_depth': [3, 5, 10]}\n",
    "}\n",
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square\n",
    "\n",
    "# Train and evaluate models with hyperparameter tuning\n",
    "best_model_info = {'model': None, 'params': None, 'performance': None}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    param_grid = param_grids[name]\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mae, rmse, r2_square = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"{name} Model Performance\")\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"R2 score\", r2_square * 100)\n",
    "    print('=' * 35)\n",
    "    print('\\n')\n",
    "\n",
    "    if best_model_info['performance'] is None or r2_square > best_model_info['performance']:\n",
    "        best_model_info['model'] = best_model\n",
    "        best_model_info['params'] = grid_search.best_params_\n",
    "        best_model_info['performance'] = r2_square\n",
    "\n",
    "# Print the best model and its performance\n",
    "best_model_name = type(best_model_info['model']).__name__\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(\"Best Parameters:\", best_model_info['params'])\n",
    "print(\"Best R2 Score:\", best_model_info['performance'] * 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessor\n",
    "with open('preprocessor.pkl', 'wb') as file:\n",
    "    pickle.dump(preprocessor, file)\n",
    "\n",
    "# Save the best model\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model_info['model'], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1328826,
     "sourceId": 7963387,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
